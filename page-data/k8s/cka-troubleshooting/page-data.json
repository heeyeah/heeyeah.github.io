{"componentChunkName":"component---src-templates-blog-post-js","path":"/k8s/cka-troubleshooting/","result":{"data":{"site":{"siteMetadata":{"title":"Heeye Blog","author":"heeye","siteUrl":"https://heeyeah.github.io","comment":{"disqusShortName":"","utterances":"heeyeah/heeyeah.github.io"},"sponsor":{"buyMeACoffeeId":"heeyeah"}}},"markdownRemark":{"id":"58d12169-f6a1-5392-bb8e-eed93e84438b","excerpt":"Application Failure application failure은, (서비스-파드) 관계가 있을 때 서비스가 파드를 잘 select하고 있는지 노출된 port는 잘 맞는지 주입된 환경변수(env)는 잘 들어갔는지 이런 것에 대해서 질의한다😎 Control Plane Failure scheduler yaml 고치기 /etc/kubernetes/manifest 밑에 있었는데, 이거 경로 찾는 과정이 있었음 (찾아보기!) kube-scheduler.yaml controller-manager…","html":"<h2 id=\"application-failure\" style=\"position:relative;\"><a href=\"#application-failure\" aria-label=\"application failure permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Application Failure</h2>\n<p>application failure은, (서비스-파드) 관계가 있을 때</p>\n<ul>\n<li>서비스가 파드를 잘 select하고 있는지</li>\n<li>노출된 port는 잘 맞는지</li>\n<li>주입된 환경변수(env)는 잘 들어갔는지</li>\n</ul>\n<p>이런 것에 대해서 질의한다😎</p>\n<h2 id=\"control-plane-failure\" style=\"position:relative;\"><a href=\"#control-plane-failure\" aria-label=\"control plane failure permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Control Plane Failure</h2>\n<h3 id=\"scheduler-yaml-고치기\" style=\"position:relative;\"><a href=\"#scheduler-yaml-%EA%B3%A0%EC%B9%98%EA%B8%B0\" aria-label=\"scheduler yaml 고치기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>scheduler yaml 고치기</h3>\n<p>/etc/kubernetes/manifest 밑에 있었는데, 이거 경로 찾는 과정이 있었음 (찾아보기!)</p>\n<p>kube-scheduler.yaml</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">containers</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">command</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> kube<span class=\"token punctuation\">-</span>scheduler\n    <span class=\"token punctuation\">-</span> <span class=\"token punctuation\">-</span><span class=\"token punctuation\">-</span>authentication<span class=\"token punctuation\">-</span>kubeconfig=/etc/kubernetes/scheduler.conf\n    <span class=\"token punctuation\">-</span> <span class=\"token punctuation\">-</span><span class=\"token punctuation\">-</span>authorization<span class=\"token punctuation\">-</span>kubeconfig=/etc/kubernetes/scheduler.conf\n    <span class=\"token punctuation\">-</span> <span class=\"token punctuation\">-</span><span class=\"token punctuation\">-</span>bind<span class=\"token punctuation\">-</span>address=127.0.0.1\n    <span class=\"token punctuation\">-</span> <span class=\"token punctuation\">-</span><span class=\"token punctuation\">-</span>kubeconfig=/etc/kubernetes/scheduler.conf\n    <span class=\"token punctuation\">-</span> <span class=\"token punctuation\">-</span><span class=\"token punctuation\">-</span>leader<span class=\"token punctuation\">-</span>elect=true\n    <span class=\"token punctuation\">-</span> <span class=\"token punctuation\">-</span><span class=\"token punctuation\">-</span>port=0</code></pre></div>\n<h3 id=\"controller-manager-고치기\" style=\"position:relative;\"><a href=\"#controller-manager-%EA%B3%A0%EC%B9%98%EA%B8%B0\" aria-label=\"controller manager 고치기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>controller-manager 고치기</h3>\n<p><code class=\"language-text\">ps -aux | grep kubelet</code> 무조건 치고 들어가서 config 파일 확인하고 static pod directory 확인!!</p>\n<ol>\n<li>static pod yaml 고치는 문제!</li>\n<li>일단 에러 난 파드 log 확인했더니 이렇게 나옵니당</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">root@controlplane:/etc/kubernetes<span class=\"token comment\"># k logs -f kube-controller-manager-controlplane -n kube-system</span>\nFlag --port has been deprecated, see --secure-port instead.\nI0803 <span class=\"token number\">13</span>:49:18.220043       <span class=\"token number\">1</span> serving.go:331<span class=\"token punctuation\">]</span> Generated self-signed cert in-memory\nunable to load client CA <span class=\"token function\">file</span> <span class=\"token string\">\"/etc/kubernetes/pki/ca.crt\"</span><span class=\"token builtin class-name\">:</span> <span class=\"token function\">open</span> /etc/kubernetes/pki/ca.crt: no such <span class=\"token function\">file</span> or directory</code></pre></div>\n<h2 id=\"worker-node-failure\" style=\"position:relative;\"><a href=\"#worker-node-failure\" aria-label=\"worker node failure permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Worker Node Failure</h2>\n<p>worker node failure인건 다 kubelet 문제네</p>\n<p><em><span style=\"color:#e449c7\"> 😈kubelet 역할 : The kubelet is the primary “node agent” that runs on each node. It can register the node with the apiserver using one of: the hostname; a flag to override the hostname; or specific logic for a cloud provider.</span></em></p>\n<p>상태 확인</p>\n<p><code class=\"language-text\">service kubelet status</code></p>\n<p>로그 확인</p>\n<p><code class=\"language-text\">sudo journalctl -u kubelet</code></p>\n<p>인증서 확인</p>\n<p><code class=\"language-text\">openssl x509 -in /var/lib/kubelet/worker-1.crt -text</code></p>\n<p>status가 False나 true이면, master에 연결은 돼있는거고, Unknown이면 master랑도 끊어진것 :)</p>\n<h3 id=\"fix-node\" style=\"position:relative;\"><a href=\"#fix-node\" aria-label=\"fix node permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>fix node!</h3>\n<p>Step1: Check the status of the nodes:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">root@controlplane:~<span class=\"token comment\"># kubectl get nodes</span>\nNAME           STATUS     ROLES                  AGE     VERSION\ncontrolplane   Ready      control-plane,master   6m38s   v1.20.0\nnode01         NotReady   <span class=\"token operator\">&lt;</span>none<span class=\"token operator\">></span>                 4m59s   v1.20.0\nroot@controlplane:~<span class=\"token comment\">#</span></code></pre></div>\n<p>Step 2: SSH to node01 and check the status of container runtime (docker, in this case) and the kubelet service.</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">root@node01:~<span class=\"token comment\"># systemctl status kubelet</span>\n● kubelet.service - kubelet: The Kubernetes Node Agent\n   Loaded: loaded <span class=\"token punctuation\">(</span>/lib/systemd/system/kubelet.service<span class=\"token punctuation\">;</span> enabled<span class=\"token punctuation\">;</span> vendor preset: enabled<span class=\"token punctuation\">)</span>\n  Drop-In: /etc/systemd/system/kubelet.service.d\n           └─10-kubeadm.conf\n   Active: inactive <span class=\"token punctuation\">(</span>dead<span class=\"token punctuation\">)</span> since Sun <span class=\"token number\">2021</span>-07-25 07:46:58 UTC<span class=\"token punctuation\">;</span> 5min ago\n     Docs: https://kubernetes.io/docs/home/\n  Process: <span class=\"token number\">1917</span> <span class=\"token assign-left variable\">ExecStart</span><span class=\"token operator\">=</span>/usr/bin/kubelet <span class=\"token variable\">$KUBELET_KUBECONFIG_ARGS</span> <span class=\"token variable\">$KUBELET_CONFIG_ARGS</span> <span class=\"token variable\">$KUBELET_KUBEADM_ARGS</span> <span class=\"token variable\">$KUBELET_EXTRA_ARGS</span> <span class=\"token punctuation\">(</span>code<span class=\"token operator\">=</span>exited,\n Main PID: <span class=\"token number\">1917</span> <span class=\"token punctuation\">(</span>code<span class=\"token operator\">=</span>exited, <span class=\"token assign-left variable\">status</span><span class=\"token operator\">=</span><span class=\"token number\">0</span>/SUCCESS<span class=\"token punctuation\">)</span></code></pre></div>\n<p>Since the kubelet is not running, attempt to start it by running:</p>\n<div class=\"gatsby-highlight\" data-language=\"shell\"><pre class=\"language-shell\"><code class=\"language-shell\">root@node01:~<span class=\"token comment\"># systemctl start kubelet</span>\nroot@node01:~<span class=\"token comment\"># systemctl status kubelet</span>\n● kubelet.service - kubelet: The Kubernetes Node Agent\n   Loaded: loaded <span class=\"token punctuation\">(</span>/lib/systemd/system/kubelet.service<span class=\"token punctuation\">;</span> enabled<span class=\"token punctuation\">;</span> vendor preset: enabled<span class=\"token punctuation\">)</span>\n  Drop-In: /etc/systemd/system/kubelet.service.d\n           └─10-kubeadm.conf\n   Active: active <span class=\"token punctuation\">(</span>running<span class=\"token punctuation\">)</span> since Sun <span class=\"token number\">2021</span>-07-25 07:53:35 UTC<span class=\"token punctuation\">;</span> 2s ago\n     Docs: https://kubernetes.io/docs/home/</code></pre></div>\n<p>node01 should go back to ready state now.</p>\n<h3 id=\"fix-cluster---1\" style=\"position:relative;\"><a href=\"#fix-cluster---1\" aria-label=\"fix cluster   1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>fix cluster - 1</h3>\n<p>생각을 해야할 게, not ready가 된 상태의 노드로 가서 점검을 해야함!</p>\n<p>kubelet has stopped running on node01 again. Since this is a systemd managed system, we can check the kubelet log by running journalctl. Here is a snippet showing the error with kubelet:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">root@node01:~# journalctl -u kubelet\n.\n.\nJul 25 07:54:50 node01 kubelet[5681]: F0725 07:54:50.831238    5681 server.go:257] unable to load client CA file /etc/kubernetes/pki/WRONG-CA-FILE.crt: open /etc/kubernetes/pki/WRONG-CA-FILE.crt: no such file or directory\nJul 25 07:55:01 node01 kubelet[5710]: F0725 07:55:01.339531    5710 server.go:257]\n.\n.</code></pre></div>\n<p>There appears to be a mistake path used for the CA certificate in the kubelet configuration. This can be corrected by updating the file <code class=\"language-text\">/var/lib/kubelet/config.yaml</code>.\nOnce this is fixed, restart the kubelet service, (like we did in the previous question) and node01 should return back to a working state.</p>\n<h3 id=\"fix-cluster---2\" style=\"position:relative;\"><a href=\"#fix-cluster---2\" aria-label=\"fix cluster   2 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>fix cluster - 2</h3>\n<p>Once again the kubelet service has stopped working. Checking the logs, we can see that this time, it is not able to reach the kube-apiserver.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">root@node01:~# journalctl -u kubelet\n.\n.\nJul 25 08:05:26 node01 kubelet[7966]: E0725 08:05:26.426155    7966 reflector.go:138] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:46: Failed to watch *v1.Pod: failed to list *v1.Pod: Get &quot;https://controlplane:6553/api/v1/pods?fieldSelector=spec.nodeName%3Dnode01&amp;limit=500&amp;resourceVersion=0&quot;: dial tcp 10.1.126.9:6553: connect: connection refused\n.\n.</code></pre></div>\n<p>As we can clearly see, kubelet is trying to connect to the API server on the <span style=\"color:#ef2323\"> controlplane node on port 6553. This is incorrect.</span>\nTo fix, correct the port on the kubeconfig file used by the kubelet.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> v1\n<span class=\"token key atrule\">clusters</span><span class=\"token punctuation\">:</span>\n<span class=\"token punctuation\">-</span> <span class=\"token key atrule\">cluster</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">certificate-authority-data</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span><span class=\"token punctuation\">-</span>REDACTED<span class=\"token punctuation\">---</span>\n    <span class=\"token key atrule\">server</span><span class=\"token punctuation\">:</span> https<span class=\"token punctuation\">:</span>//controlplane<span class=\"token punctuation\">:</span><span class=\"token number\">6443</span></code></pre></div>\n<p>Restart the kubelet after this change.</p>\n<h2 id=\"network-troubleshooting\" style=\"position:relative;\"><a href=\"#network-troubleshooting\" aria-label=\"network troubleshooting permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Network Troubleshooting</h2>","frontmatter":{"title":"[CKA] Trouble Shooting!","date":"August 02, 2021"}}},"pageContext":{"slug":"/k8s/cka-troubleshooting/","previous":{"fields":{"slug":"/k8s/cka-networking/"},"frontmatter":{"title":"[CKA] Section9. Networking","category":"k8s","draft":false}},"next":null}},"staticQueryHashes":["3128451518","521680639"]}